{
  "hash": "33cdfa2f465b2d27e3a4b2654cc2e44e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Doubly Robust Estimation of Causal Effects in Survival Analysis\"\nauthor: \"Peirong Hao, Ravinder Singh, Kevin Ying, Adam Bress, Tom Greene, Yizhe Xu^[Corresponding author: yizhe.xu@hsc.utah.edu]\"\ndate: \"2026-01-25\"\n#output: rmarkdown::html_vignette\noutput:\n  html_document:\n    mathjax: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nbibliography: references_DR.bib  \n#csl: harvard-cite-them-right.csl\nlink-citations: true\nobjective: Estimate treatment effects on time-to-event outcomes under noninformative censoring using doubly robust methods \nvignette: >\n  \\VignetteIndexEntry{Doubly Robust Estimation of Causal Effects on Time-to-event Outcomes}\n  %\\VignetteEncoding{UTF-8}\n  %\\VignetteEngine{knitr::rmarkdown}\neditor_options: \n  markdown: \n    wrap: sentence\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  message = FALSE,    \n  warning = FALSE     \n)\n\nset.seed(123456)\nlibrary(truncnorm)\nlibrary(survival)\nlibrary(pseudo)\nlibrary(adjustedCurves)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(dagitty)\nlibrary(parallel)\nlibrary(future.apply)\nlibrary(future)\n\nn_cores <- detectCores() - 2\n```\n:::\n\n\n## Introduction\n\nAs noted in @DR-main, estimating causal effects of a treatment in observational studies is challenging due to confounding bias.\nCommon approaches to controlling for confounding include *outcome regression* and *propensity score methods*.\n\n-   *Outcome regression methods* model the conditional expectation of the outcome given treatment and baseline covariates.\n    Marginal outcome means for each treatment strategy are then obtained by setting treatment to “treated” or “control” for all subjects and averaging over the covariate distribution.\n    The difference in these marginal means is a commonly used estimand for the average treatment effect (ATE).\n\n-   *Propensity score methods* first estimate the propensity score (PS), i.e., the probability of receiving treatment given covariates, and then apply inverse probability weighting to construct a pseudo-population in which treatment is independent of measured confounders.\n\nBoth approaches rely on correctly specified outcome or propensity score models, and misspecification of either can lead to biased estimates.\n\n## Doubly Robust Estimation\n\nDoubly robust (DR) estimation leverages both the **outcome regression model** and the **propensity score model**.\nConsider $n$ independent and identically distributed individuals indexed by $i$.\nLet $D$ denote a binary treatment (0 or 1), $Y$ the outcome of interest without censoring, and $\\boldsymbol{Z} = (Z_1, Z_2, \\ldots, Z_k)$ a set of baseline covariates.\nLet $\\hat{e}(\\boldsymbol{Z})$ be the estimated propensity score and $\\hat{m}_d(\\boldsymbol{Z})$ be the predicted outcome given $D$ and $\\boldsymbol{Z}$.\nThe DR estimator for the average treatment effect (ATE) is\n\n$$\n\\hat{\\tau}_{DR} = \\frac{1}{n} \\sum_{i=1}^n \n\\left[\n  \\frac{D_i Y_i}{\\hat{e}(\\boldsymbol{Z}_i)} \n  - \\frac{(D_i - \\hat{e}(\\boldsymbol{Z}_i))}{\\hat{e}(\\boldsymbol{Z}_i)} \\hat{m}_1(\\boldsymbol{Z}_i)\n\\right]\n-\n\\left[\n  \\frac{(1 - D_i) Y_i}{1 - \\hat{e}(\\boldsymbol{Z}_i)} \n  + \\frac{(D_i - \\hat{e}(\\boldsymbol{Z}_i))}{1 - \\hat{e}(\\boldsymbol{Z}_i)} \\hat{m}_0(\\boldsymbol{Z}_i)\n\\right].\n$$\n\nThe DR estimator is also known as the **augmented inverse probability weighting (AIPW)** estimator.\nIn this form, the second term in each bracket serves as the augmentation term that converges to zero when either the PS model or outcome models are correctly specified.\nThe **doubly robustness** property ensures that the estimator remains unbiased as long as either the PS model or the outcome models are correctly specified.\nIntuitively, The DR estimator adds another layer of protection against model misspecification, which is crucial in observational studies.\nFor detailed mathematical derivations, please refer to @DR-main.\n\nIf both PS and outcome models are correctly specified, the estimator is **semiparametric efficient** [@DR-semiparam], meaning it attains the smallest possible variance among all regular, asymptotically unbiased estimators for the ATE.\nOne caveat is that if either model is misspecified, the DR estimator for ATE remains unbiased, but the resulting estimator for variance is biased.\nIn such cases, a bootstrap estimator of the asymptotic variance is recommended [@Bai2013].\n\nThe DR estimator requires standard identifiability assumptions in causal inference, including the stable unit treatment value assumption (SUTVA), positivity, consistency, and exchangeability.\n\nFor doubly robust estimators for continuous and binary outcomes, please refer to the [AIPW](https://cran.r-project.org/web/packages/AIPW/AIPW.pdf) R package from @zhong_aipw_2021.\n\n## Extension to Survival Analysis\n\nTime-to-event outcomes are common in biomedical research and are often subject to right censoring due to loss to follow-up.\nIn some situations, loss to follow-up occurs completely at random, known as *noninformative censoring*, which represents the simpler case.\nMore often, the loss to follow-up depends on pre-baseline and post-baseline characteristics, referred to as *informative censoring*.\nFor example, patients who are sicker at baseline or who develop treatment-related adverse events may be more likely to drop out early.\nIn such situations, the censoring mechanism must be explicitly modeled as a function of baseline and time-dependent covariates.\nIn this tutorial, we introduce a DR estimator for the simpler scenario with noninformative censoring under an observational study setting.\nWe will discuss an alternative DR estimator for the informative censoring case in a future tutorial.\n\n### Pseudo-observation-based DR estimator\n\nWe introduce additional notations to discuss right-censored outcomes.\nLet $T$ denote the survival time, $C$ the censoring time, and $S_d(t)$ the survival function under treatment $d$ at time $t$.\nWe define the ATE as the difference in survival probabilities between treatment groups at time $t$, i.e., $S_1(t)-S_0(t)$.\n\nAssuming loss to follow-up is completely at random, i.e., $C \\perp T^{(d)}$, @DR-pseudo proposed a DR estimator using pseudo observations.\nThe first step is to construct pseudo-observations for the survival function at time $t$ using the Kaplan–Meier (KM) estimator: $$\\hat{S}_d^{i}(t) = n \\hat{S}_d(t) - (n - 1) \\hat{S}^{-i}_{d}(t),$$ where $\\hat{S}_d(t)$ is the KM estimate using all observations and $\\hat{S}^{-i}_d(t)$ is the leave-one-out KM estimate with subject $i$ removed.\nThe pseudo-values $\\hat{S}_d^{i}(t)$ are (asymptotically) individual-level contributions such that $E[\\hat{S}_d^{i}(t)|Z_i] \\approx \\hat{S}_d(t|Z_i)$.\n\nThen, these pseudo-values replace the observed outcome $Y_i$ and act as censoring-adjusted outcomes under the assumption of random censoring.\nWith $\\hat{S}_d^{i}(t)$ treated as the outcome, a standard DR estimator is then applied using a PS model and an outcome regression model.\nThe pseudo-observation-based DR estimator for ATE is: $$\n\\hat{\\tau}^{pseudo}_{DR} = \\frac{1}{n} \\sum_{i=1}^n \n\\left[\n  \\frac{D_i \\hat{S}_d^i(t)}{\\hat{e}(\\boldsymbol{Z}_i)} \n  - \\frac{(D_i - \\hat{e}(\\boldsymbol{Z}_i))}{\\hat{e}(\\boldsymbol{Z}_i)} \\hat{m}_1(t, \\boldsymbol{Z}_i)\n\\right]\n-\n\\left[\n  \\frac{(1 - D_i) \\hat{S}_d^i(t)}{1 - \\hat{e}(\\boldsymbol{Z}_i)} \n  + \\frac{(D_i - \\hat{e}(\\boldsymbol{Z}_i))}{1 - \\hat{e}(\\boldsymbol{Z}_i)} \\hat{m}_0(t, \\boldsymbol{Z}_i)\n\\right],\n$$ where $\\hat{m}_d(t, \\boldsymbol{Z}_i)$ can be estimated using a Cox proportional hazards model and $\\hat{e}(\\boldsymbol{Z}_i))$ can be estimated using logistic regression.\nThe variance of the resulting estimator can be obtained based on Equation (17) in @DR-pseudo.\n\n## Implementation of the DR estimator\n\nWe now demonstrate how to implement the pseudo-observation-based DR estimator under the random censoring scenario.\n\n### Data Generation\n\nWe first simulate the data according to the variable relationships depicted in the directed acyclic graph (DAG) below\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag <- dagitty(\"dag {\n  Z1 -> Treatment\n  Z2 -> Treatment\n  Z3 -> Treatment\n  Z1 -> Death\n  Z2 -> Death\n  Z3 -> Death\n  Z4 -> Death\n  Treatment -> Death\n}\")\n\ncoordinates(dag) <- list(x = c(Z1 = 0, Z2 = 0.5, Z3 = 0, Z4 = 1.5, Treatment = 0.5, Death = 1.5),\n                         y = c(Z1 = 1, Z2 = 0.7, Z3 = 0, Z4 = 0, Treatment = 0.35, Death = 0.35))\n\nplot(dag)\n```\n\n::: {.cell-output-display}\n![](DRpseudo_files/figure-html/unnamed-chunk-1-1.png){width=288}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha_0 <- -0.2\nalpha_Z1 <- 0.6\nalpha_Z2 <- 1.6\nalpha_Z3 <- 1.6\nalpha_Z1Z2 <- 0.8\nalpha_Z2sq <- 0.5\n\nbeta_0 <- -2.6      \nbeta_D <- -0.8 \nbeta_Z1 <- 0.2 \nbeta_Z2 <- 1.9\nbeta_Z3 <- 1.9 \nbeta_Z4 <- 0.2\nbeta_Z2sq <- 0.8\nbeta_Z1Z3 <- 0.8\n\ngenerate_data_noninf <- function(n = 500) {\n  Z1 <- rnorm(n, 0, 1)\n  Z2 <- rnorm(n, 0, 1)\n  Z3 <- rnorm(n, 0, 1)\n  Z4 <- rnorm(n, 0, 2) \n  Z5 <- rnorm(n, 0, 2.5)\n  Z6 <- rnorm(n, 0, 1)\n  Z7 <- rnorm(n, 0, 1)\n  Z8 <- rnorm(n, 0, 1)\n  Z9 <- rnorm(n, 0, 1)\n  \n  logit_p <- (alpha_0 + alpha_Z1 * Z1 + alpha_Z2 * Z2 + alpha_Z3 * Z3 + alpha_Z1Z2 * (Z1 * Z2) + alpha_Z2sq * (Z2^2)) / 2.8\n  p <- plogis(logit_p) # exp(logit_p) / (1 + exp(logit_p))\n  D <- rbinom(n, 1, p) # Treatment indicator\n  \n  hazard <- exp(beta_0 + beta_D * D + beta_Z1 * Z1 + beta_Z2 * Z2 + beta_Z3 * Z3 + beta_Z4 * Z4 + beta_Z2sq * (Z2^2) + beta_Z1Z3 * (Z1 * Z3))\n  T_event <- rexp(n, rate = hazard) # Event time from an exponential model\n  #summary(T_event)\n  \n  T_censor <- rexp(n, rate = exp(-3)) # Censoring time based on random censoring\n  #summary(T_censor)\n  T_admin <- rep(5, n) # Administrative (random) censoring\n  \n  Time <- pmin(T_event, T_censor, T_admin) # Observed follow-up time\n  Event <- as.numeric(T_event <= T_censor & T_event <= T_admin) # Event indicator\n  \n  return(data.frame(Z1 = Z1, Z2 = Z2, Z3 = Z3, Z4 = Z4, Z5 = Z5, Z6 = Z6, Z7 = Z7, Z8 = Z8, Z9 = Z9, D = D, Time = Time, Event = Event))\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- generate_data_noninf()\n\nattr(data$Z1, \"label\") <- \"Baseline value of Z1\"\nattr(data$Z2, \"label\") <- \"Baseline value of Z2\"\nattr(data$Z3, \"label\") <- \"Baseline value of Z3\"\nattr(data$Z4, \"label\") <- \"Baseline value of Z4\"\nattr(data$Z5, \"label\") <- \"Baseline value of Z5\"\nattr(data$Z6, \"label\") <- \"Baseline value of Z6\"\nattr(data$Z7, \"label\") <- \"Baseline value of Z7\"\nattr(data$Z8, \"label\") <- \"Baseline value of Z8\"\nattr(data$Z9, \"label\") <- \"Baseline value of Z9\"\nattr(data$D, \"label\") <- \"Treatment indicator (1 = treated, 0 = control)\"\nattr(data$Time, \"label\") <- \"Time index for longitudinal records\"\nattr(data$Event, \"label\") <- \"Event indicator (1 = event occurred, 0 = otherwise)\"\n\nget_label <- function(x) {\n  lbl <- attr(x, \"label\", exact = TRUE)\n  if (is.null(lbl)) \"\" else as.character(lbl)\n}\n\ndict <- data.frame(\n  Variable = names(data),\n  Meaning  = vapply(data, get_label, character(1)),\n  check.names = FALSE\n)\n\nknitr::kable(dict, caption = \"Data Dictionary\", row.names = FALSE) \n```\n\n::: {.cell-output-display}\n\n\nTable: Data Dictionary\n\n|Variable |Meaning                                             |\n|:--------|:---------------------------------------------------|\n|Z1       |Baseline value of Z1                                |\n|Z2       |Baseline value of Z2                                |\n|Z3       |Baseline value of Z3                                |\n|Z4       |Baseline value of Z4                                |\n|Z5       |Baseline value of Z5                                |\n|Z6       |Baseline value of Z6                                |\n|Z7       |Baseline value of Z7                                |\n|Z8       |Baseline value of Z8                                |\n|Z9       |Baseline value of Z9                                |\n|D        |Treatment indicator (1 = treated, 0 = control)      |\n|Time     |Time index for longitudinal records                 |\n|Event    |Event indicator (1 = event occurred, 0 = otherwise) |\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(data$Time)\n#>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n#> 0.000053 0.668455 3.640693 2.968875 5.000000 5.000000\n\ntable(data$Event)\n#> \n#>   0   1 \n#> 286 214\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncensored_subjects <- data[data$Event == 0, ]\n(early_dropout <- sum(censored_subjects$Time < 5))\n#> [1] 74\n(admin_censored <- sum(censored_subjects$Time >= 5))\n#> [1] 212\n```\n:::\n\n\nAmong the 286 subjects with no events, 74 are early dropouts and 212 are administratively censored.\nAdministrative censoring is random, so no additional modeling is needed.\nEarly dropout could be covariate-dependent or occur completely at random, and we assume it is non-informative in this data generation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnrow(data[data$Event == 1 & data$Time <= 3, ])\n#> [1] 190\n```\n:::\n\n\nWith the simulation above, we can calculate the true survival probability.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_true_survival <- function(data, t, D) {\n  hazard <- exp(beta_0 + beta_D * D + beta_Z1 * data$Z1 + beta_Z2 * data$Z2 + beta_Z3 * data$Z3 + beta_Z4 * data$Z4 + \n            beta_Z2sq * (data$Z2^2) + beta_Z1Z3 * (data$Z1 * data$Z3))\n  survival_probs <- exp(-hazard * t) # baseline hazard is constant under an expotential survival model\n  return(mean(survival_probs)) \n}\n```\n:::\n\n\nWe generate multiple datasets to compute the true ATEs at prespecified time points and corresponding 95% confidence intervals (CIs) using percentiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_datasets <- 100\ndatasets <- replicate(n_datasets, generate_data_noninf(), simplify = FALSE)\n\ntimes <- c(1, 2, 3)\ntrue_ate_samples <- matrix(NA, nrow = n_datasets, ncol = length(times))\n\nfor (i in 1:n_datasets) {\n  # Compute potential survival probabilities by setting treatment to 1 and 0 for all individuals\n  true_surv_1 <- sapply(times, function(t) get_true_survival(datasets[[i]], t, D = 1))\n  true_surv_0 <- sapply(times, function(t) get_true_survival(datasets[[i]], t, D = 0))\n  \n  # Calculate ATE as difference in survival probabilities\n  true_ate_samples[i, ] <- true_surv_1 - true_surv_0\n}\n\ntrue_ate_mean <- colMeans(true_ate_samples)\ntrue_ate_ci_lower <- apply(true_ate_samples, 2, quantile, probs = 0.025)\ntrue_ate_ci_upper <- apply(true_ate_samples, 2, quantile, probs = 0.975)\n\nresults_true <- list(ATE = true_ate_mean, ci_lower = true_ate_ci_lower, ci_upper = true_ate_ci_upper)\n\ntrue_ate_with_ci <- sapply(1:length(times), function(i) {\n  sprintf(\"%.3f (%.3f, %.3f)\", results_true$ATE[i], results_true$ci_lower[i], results_true$ci_upper[i])\n})\n```\n:::\n\n\n### Using R package\n\nFirst, we implement the pseudo-observation-based DR estimator using the *adjustedsurv* function in the [adjustedCurves](https://cran.r-project.org/web/packages/adjustedCurves/adjustedCurves.pdf) R package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npseudo_dr_ate_pkg <- function(data, times, ps_correct = TRUE, or_correct = TRUE, use_bootstrap = TRUE) {\n  \n  data$D <- factor(data$D, levels = c(0, 1))\n  \n  # Propensity score model\n  if (ps_correct) {\n    ps_model <- glm(D ~ Z1 + Z2 + Z3 + I(Z2^2) + I(Z1*Z2), data = data, family = \"binomial\")\n  } else {\n    ps_model <- glm(D ~ I(Z5 * Z6) + I(Z7 * Z8) + Z9 + I(Z9^2), data = data, family = \"binomial\")\n  }\n\n  # Covariates used in the outcome model\n  if (or_correct) {\n    data$Z1_Z3 <- data$Z1 * data$Z3\n    data$Z2sq <- data$Z2 * data$Z2\n    or_covars <- c(\"Z1\", \"Z2\", \"Z3\", \"Z4\", \"Z1_Z3\", \"Z2sq\")\n  } else {\n    or_covars <- c(\"Z5\")\n  }\n\n  # Pseudo-observation-based DR estimator for survival probabilities \n  # This method uses a generalized estimation equation for outcome model\n  adj_surv <- adjustedsurv(\n    data = data,\n    variable = \"D\",\n    ev_time = \"Time\",\n    event = \"Event\",\n    method = \"aiptw_pseudo\",\n    treatment_model = ps_model,\n    outcome_vars = or_covars,\n    times = times, \n    conf_int = TRUE,\n    bootstrap = use_bootstrap,\n    n_boot = 100, # In practice, set n_boot to a larger value (e.g., 1000).\n    n_cores = if(use_bootstrap) n_cores else 1) \n  \n  # Treatment effect is defined as the difference in survival probabilities.\n  ate_results <- adjusted_curve_diff(\n    adj = adj_surv,\n    group_1 = \"1\",  # Treated group\n    group_2 = \"0\",  # Control group\n    conf_int = TRUE,\n    conf_level = 0.95)\n  \n  ate_at_times <- ate_results[ate_results$time %in% times, ]\n  \n  return(list(ATE = ate_at_times$diff, ci_lower = ate_at_times$ci_lower, ci_upper = ate_at_times$ci_upper))\n}\n```\n:::\n\n\nWe estimate the ATEs at prespecified time points and corresponding 95% CIs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults_package <- pseudo_dr_ate_pkg(data, times)  \n\nate_with_ci <- sapply(1:length(times), function(i) {\n  sprintf(\"%.3f (%.3f, %.3f)\", results_package$ATE[i], results_package$ci_lower[i], results_package$ci_upper[i])\n})\n\nresults_manual_tbl <- data.frame(\n  ATE = c(\"Estimated\", \"True\"),\n  `T = 1` = c(ate_with_ci[1], true_ate_with_ci[1]), \n  `T = 2` = c(ate_with_ci[2], true_ate_with_ci[2]),\n  `T = 3` = c(ate_with_ci[3], true_ate_with_ci[3]), \n  check.names = FALSE)\n\nkable(results_manual_tbl, caption = \"ATE (95% CI)\", align = c('c', 'c', 'c', 'c')) %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">ATE (95% CI)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> ATE </th>\n   <th style=\"text-align:center;\"> T = 1 </th>\n   <th style=\"text-align:center;\"> T = 2 </th>\n   <th style=\"text-align:center;\"> T = 3 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Estimated </td>\n   <td style=\"text-align:center;\"> 0.127 (0.060, 0.194) </td>\n   <td style=\"text-align:center;\"> 0.047 (-0.026, 0.120) </td>\n   <td style=\"text-align:center;\"> 0.069 (-0.006, 0.145) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> True </td>\n   <td style=\"text-align:center;\"> 0.074 (0.068, 0.082) </td>\n   <td style=\"text-align:center;\"> 0.087 (0.079, 0.094) </td>\n   <td style=\"text-align:center;\"> 0.094 (0.085, 0.102) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Manual coding\n\nThe pseudo-observation-based DR estimator can be implemented manually\n\n-   We use a Cox regression for the outcome model rather than GEE as in the package above\n\n\n::: {.cell}\n\n```{.r .cell-code}\npseudo_dr_ate_manual <- function(data, times, ps_correct = TRUE, or_correct = TRUE) {\n  \n  # Outcome regression (Cox proportional hazard model)\n  if (or_correct) {\n    or_model <- coxph(Surv(Time, Event) ~ D + Z1 + Z2 + Z3 + Z4 + I(Z2^2) + I(Z1 * Z3), data = data)\n  } else {\n    or_model <- coxph(Surv(Time, Event) ~ Z5, data = data)\n  }\n  \n  data1 <- data\n  data1$D <- 1\n  \n  data0 <- data\n  data0$D <- 0\n  \n  # Extract the linear predictors (Beta^T * Z) from fitted Cox models \n  lp_1 <- predict(or_model, newdata = data1, type = \"lp\")\n  lp_0 <- predict(or_model, newdata = data0, type = \"lp\")\n  \n  # Baseline survival functions\n  bh <- basehaz(or_model, centered = FALSE)\n  bh$surv <- exp(-bh$hazard)\n  \n  # Baseline survival probabilities at different times\n  s0_f <- stepfun(bh$time, c(1, bh$surv))\n  s0_t <- s0_f(times)\n  \n  # Predicted survival probabilities\n  m1 <- sapply(s0_t, function(s0) s0 ^ exp(lp_1))\n  m0 <- sapply(s0_t, function(s0) s0 ^ exp(lp_0))\n  \n  # Propensity scores\n  if (ps_correct) {\n    ps_model <- glm(D ~ Z1 + Z2 + Z3 + I(Z2^2) + I(Z1*Z2), data = data, family = \"binomial\")\n  } else {\n    ps_model <- glm(D ~ I(Z5 * Z6) + I(Z7 * Z8) + Z9 + I(Z9^2), data = data, family = \"binomial\")\n  }\n  e <- predict(ps_model, type = \"response\")\n  \n  # Pseudo-observations (individual estimates of the survival function at specified time points)\n  pseudo_obs <- pseudosurv(time = data$Time, event = data$Event, tmax = times)$pseudo\n  \n  surv_1 <- numeric(length(times))\n  surv_0 <- numeric(length(times))\n  ATE <- numeric(length(times))\n  \n  for(j in 1:length(times)) {\n    # DR for treated group\n    term1_treated <- data$D * pseudo_obs[, j] / e\n    term2_treated <- (data$D - e) * m1[, j] / e\n    term_full_treated <- term1_treated - term2_treated\n    surv_1[j] <- mean(term_full_treated)\n    \n    # DR for control group  \n    term1_control <- (1 - data$D) * pseudo_obs[, j] / (1 - e)\n    term2_control <- (data$D - e) * m0[, j] / (1 - e)\n    term_full_control <- term1_control + term2_control\n    surv_0[j] <- mean(term_full_control) \n    \n    ATE[j] <- surv_1[j] - surv_0[j]\n  }\n  return(list(ATE = ATE))\n}\n```\n:::\n\n\nWe calculate the standard error (SE) of the ATE using bootstrapping\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse_bootstrap <- function(data, times, num_boot = 100) {\n  # In practice, set n_boot to a larger value (e.g., 1000).\n  n <- nrow(data)\n  boot_results <- matrix(NA, nrow = num_boot, ncol = length(times))\n\n  for (b in 1:num_boot) {\n    boot_indices <- sample(1:n, size = n, replace = TRUE)\n    boot_data <- data[boot_indices, ]\n    boot_results[b, ] <- pseudo_dr_ate_manual(data = boot_data, times = times)$ATE\n  }\n\n  se <- apply(boot_results, 2, sd, na.rm = TRUE)\n  return(list(se = se))\n}\n```\n:::\n\n\nWe calculate the 95% CI of the ATE using parametric bootstrapping assuming ATE is normally distributed\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults_manual <- pseudo_dr_ate_manual(data, times)  \nse_manual <- se_bootstrap(data, times)\n\n# Calculate 95% confidence intervals\nresults_manual$ci_lower <- results_manual$ATE - 1.96 * se_manual$se\nresults_manual$ci_upper <- results_manual$ATE + 1.96 * se_manual$se\n\nate_with_ci <- sapply(1:length(times), function(i) {\n  sprintf(\"%.3f (%.3f, %.3f)\", results_manual$ATE[i], \n  results_manual$ci_lower[i], results_manual$ci_upper[i])})\n\nresults_manual_tbl <- data.frame(\n  ATE = c(\"Estimated\", \"True\"),\n  `T = 1` = c(ate_with_ci[1], true_ate_with_ci[1]), \n  `T = 2` = c(ate_with_ci[2], true_ate_with_ci[2]),\n  `T = 3` = c(ate_with_ci[3], true_ate_with_ci[3]), \n  check.names = FALSE)\n\nkable(results_manual_tbl, caption = \"ATE (95% CI)\", align = c('c', 'c', 'c', 'c')) %>% \n  kable_styling(full_width = FALSE, font_size = 12)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">ATE (95% CI)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:center;\"> ATE </th>\n   <th style=\"text-align:center;\"> T = 1 </th>\n   <th style=\"text-align:center;\"> T = 2 </th>\n   <th style=\"text-align:center;\"> T = 3 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> Estimated </td>\n   <td style=\"text-align:center;\"> 0.116 (0.053, 0.178) </td>\n   <td style=\"text-align:center;\"> 0.050 (-0.016, 0.116) </td>\n   <td style=\"text-align:center;\"> 0.079 (0.016, 0.142) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> True </td>\n   <td style=\"text-align:center;\"> 0.074 (0.068, 0.082) </td>\n   <td style=\"text-align:center;\"> 0.087 (0.079, 0.094) </td>\n   <td style=\"text-align:center;\"> 0.094 (0.085, 0.102) </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Crude estimation\n\nFit a crude Cox model with no covariate or propensity score adjustment to show the amount of confounding bias in our data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrude_cox_estimator <- function(data, times) {\n\n  crude_cox <- coxph(Surv(Time, Event) ~ D, data = data)\n  treatment_effect <- coef(crude_cox)[\"D\"]\n  \n  base_surv <- survfit(crude_cox)\n  s0 <- summary(base_surv, times = times, extend = TRUE)$surv\n  \n  # Survival for treated group: S_baseline^exp(beta_D)\n  surv_1 <- s0^exp(treatment_effect)\n  \n  # Survival for control group: S_baseline^exp(0) \n  surv_0 <- s0\n  \n  ATE <- surv_1 - surv_0\n\n  return(list(ATE = ATE))\n}\n\nresults_crude <- crude_cox_estimator(data, times)\n```\n:::\n\n\n### Evaluate the performance of pseudo-observation-based DR estimator\n\nWe use the datasets generated previously to calculate RMSE, bias, and variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = n_cores)\n\ncalculate_metrics <- function(datasets, true_ate_samples, times, method = \"package\", ps_correct = TRUE, or_correct = TRUE) {\n  \n  n_datasets <- length(datasets)\n  \n  ate <- future_lapply(1:n_datasets, function(i) {\n    library(survival)\n    library(pseudo)\n    library(adjustedCurves)\n    \n    est_results <- switch(\n      method,\n      \"package\" = pseudo_dr_ate_pkg(datasets[[i]], times, ps_correct = ps_correct, or_correct = or_correct,\n                                    use_bootstrap = FALSE),\n      \"manual\" = pseudo_dr_ate_manual(datasets[[i]], times, ps_correct = ps_correct, or_correct = or_correct),\n      \"crude\" = crude_cox_estimator(datasets[[i]], times),\n      stop(\"Unknown: \", method))\n    \n    est_results$ATE\n  }, future.seed = TRUE)\n  \n  ate_all <- do.call(rbind, ate)\n  \n  bias <- colMeans(ate_all - true_ate_samples)\n  variance <- apply(ate_all, 2, var)\n  rmse <- sqrt(colMeans((ate_all - true_ate_samples)^2))\n  \n  return(list(bias = bias, variance = variance, rmse = rmse))\n}\n```\n:::\n\n\n### Model misspecification scenarios\n\nTo illustrate the robustness of the DR estimator to model misspecification, we compare 4 scenarios:\n\n-   Scenario 1: Both the outcome model and the propensity score model are correctly specified.\n\n-   Scenario 2: The propensity score model is correctly specified, but the outcome model is misspecified.\n\n-   Scenario 3: The outcome model is correctly specified, while the propensity score model is misspecified.\n\n-   Scenario 4: Both models are misspecified.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmetrics_1_package <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", \n                                       ps_correct = TRUE, or_correct = TRUE)\nmetrics_2_package <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", \n                                       ps_correct = TRUE, or_correct = FALSE)\nmetrics_3_package <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", \n                                       ps_correct = FALSE, or_correct = TRUE)\nmetrics_4_package <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", \n                                       ps_correct = FALSE, or_correct = FALSE)\n\nmetrics_1_manual <- calculate_metrics(datasets, true_ate_samples, times, method = \"manual\", \n                                      ps_correct = TRUE, or_correct = TRUE)\nmetrics_2_manual <- calculate_metrics(datasets, true_ate_samples, times, method = \"manual\", \n                                      ps_correct = TRUE, or_correct = FALSE)\nmetrics_3_manual <- calculate_metrics(datasets, true_ate_samples, times, method = \"manual\", \n                                      ps_correct = FALSE, or_correct = TRUE)\nmetrics_4_manual <- calculate_metrics(datasets, true_ate_samples, times, method = \"manual\", \n                                      ps_correct = FALSE, or_correct = FALSE)\n\nmetrics_crude <- calculate_metrics(datasets, true_ate_samples, times, method = \"crude\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscenarios <- c(\n  \"0: Crude Cox (Unadjusted)\",\n  \"1: Both Correct\",\n  \"2: PS Correct, OR Incorrect\",\n  \"3: PS Incorrect, OR Correct\",\n  \"4: Both Incorrect\")\n\n# Combine values across all time points into a single string\nformat_values <- function(vec) {\n  paste(sprintf(\"%.4f\", vec), collapse = \", \")\n}\n\n# RMSE table\nrmse_package <- c(\"—\", format_values(metrics_1_package$rmse), format_values(metrics_2_package$rmse), \n                  format_values(metrics_3_package$rmse), format_values(metrics_4_package$rmse))\n\nrmse_manual <- c(format_values(metrics_crude$rmse), format_values(metrics_1_manual$rmse), \n                 format_values(metrics_2_manual$rmse), format_values(metrics_3_manual$rmse), \n                 format_values(metrics_4_manual$rmse))\n\nrmse_table <- data.frame(Scenario = scenarios, Package = rmse_package, Manual = rmse_manual)\n\nkable(rmse_table,\n      col.names = c(\"Scenario\", \"T = 1, 2, 3\", \"T = 1, 2, 3\"),\n      caption = \"Performance of the estimator (RMSE)\",\n      align = c('c', 'c', 'c')) %>%\n  kable_styling(full_width = FALSE, font_size = 12) %>%\n  add_header_above(c(\" \" = 1, \"Package\" = 1, \"Manual\" = 1))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Performance of the estimator (RMSE)</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Package</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Manual</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:center;\"> Scenario </th>\n   <th style=\"text-align:center;\"> T = 1, 2, 3 </th>\n   <th style=\"text-align:center;\"> T = 1, 2, 3 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 0: Crude Cox (Unadjusted) </td>\n   <td style=\"text-align:center;\"> — </td>\n   <td style=\"text-align:center;\"> 0.1883, 0.2243, 0.2450 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1: Both Correct </td>\n   <td style=\"text-align:center;\"> 0.0247, 0.0270, 0.0266 </td>\n   <td style=\"text-align:center;\"> 0.0257, 0.0277, 0.0287 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2: PS Correct, OR Incorrect </td>\n   <td style=\"text-align:center;\"> 0.0376, 0.0346, 0.0346 </td>\n   <td style=\"text-align:center;\"> 0.0364, 0.0337, 0.0337 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3: PS Incorrect, OR Correct </td>\n   <td style=\"text-align:center;\"> 0.0253, 0.0268, 0.0272 </td>\n   <td style=\"text-align:center;\"> 0.0367, 0.0330, 0.0324 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4: Both Incorrect </td>\n   <td style=\"text-align:center;\"> 0.2178, 0.2348, 0.2431 </td>\n   <td style=\"text-align:center;\"> 0.2176, 0.2346, 0.2429 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bias table\nbias_package <- c(\"—\", format_values(metrics_1_package$bias), format_values(metrics_2_package$bias), \n                  format_values(metrics_3_package$bias), format_values(metrics_4_package$bias))\n\nbias_manual <- c(format_values(metrics_crude$bias), format_values(metrics_1_manual$bias), \n                 format_values(metrics_2_manual$bias), format_values(metrics_3_manual$bias), \n                 format_values(metrics_4_manual$bias))\n\nbias_table <- data.frame(Scenario = scenarios, Package = bias_package, Manual = bias_manual)\n\nkable(bias_table,\n      col.names = c(\"Scenario\", \"T = 1, 2, 3\", \"T = 1, 2, 3\"),\n      caption = \"Performance of the estimator (Bias)\",\n      align = c('c', 'c', 'c')) %>%\n  kable_styling(full_width = FALSE, font_size = 12) %>%\n  add_header_above(c(\" \" = 1, \"Package\" = 1, \"Manual\" = 1))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Performance of the estimator (Bias)</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Package</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Manual</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:center;\"> Scenario </th>\n   <th style=\"text-align:center;\"> T = 1, 2, 3 </th>\n   <th style=\"text-align:center;\"> T = 1, 2, 3 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 0: Crude Cox (Unadjusted) </td>\n   <td style=\"text-align:center;\"> — </td>\n   <td style=\"text-align:center;\"> -0.1854, -0.2210, -0.2415 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1: Both Correct </td>\n   <td style=\"text-align:center;\"> 0.0011, 0.0035, 0.0027 </td>\n   <td style=\"text-align:center;\"> 0.0014, 0.0038, 0.0029 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2: PS Correct, OR Incorrect </td>\n   <td style=\"text-align:center;\"> -0.0001, 0.0026, 0.0020 </td>\n   <td style=\"text-align:center;\"> 0.0001, 0.0027, 0.0021 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3: PS Incorrect, OR Correct </td>\n   <td style=\"text-align:center;\"> 0.0010, 0.0034, 0.0026 </td>\n   <td style=\"text-align:center;\"> -0.0247, -0.0176, -0.0136 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4: Both Incorrect </td>\n   <td style=\"text-align:center;\"> -0.2141, -0.2309, -0.2391 </td>\n   <td style=\"text-align:center;\"> -0.2138, -0.2306, -0.2389 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Variance table\nvar_package <- c(\"—\", format_values(metrics_1_package$variance), format_values(metrics_2_package$variance), \n                 format_values(metrics_3_package$variance), format_values(metrics_4_package$variance))\n\nvar_manual <- c(format_values(metrics_crude$variance), format_values(metrics_1_manual$variance), \n                format_values(metrics_2_manual$variance), format_values(metrics_3_manual$variance), \n                format_values(metrics_4_manual$variance))\n\nvar_table <- data.frame(Scenario = scenarios, Package = var_package, Manual = var_manual)\n\nkable(var_table,\n      col.names = c(\"Scenario\", \"T = 1, 2, 3\", \"T = 1, 2, 3\"),\n      caption = \"Performance of the estimator (Variance)\",\n      align = c('c', 'c', 'c')) %>%\n  kable_styling(full_width = FALSE, font_size = 12) %>%\n  add_header_above(c(\" \" = 1, \"Package\" = 1, \"Manual\" = 1))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption style=\"font-size: initial !important;\">Performance of the estimator (Variance)</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Package</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Manual</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:center;\"> Scenario </th>\n   <th style=\"text-align:center;\"> T = 1, 2, 3 </th>\n   <th style=\"text-align:center;\"> T = 1, 2, 3 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 0: Crude Cox (Unadjusted) </td>\n   <td style=\"text-align:center;\"> — </td>\n   <td style=\"text-align:center;\"> 0.0011, 0.0014, 0.0018 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1: Both Correct </td>\n   <td style=\"text-align:center;\"> 0.0006, 0.0008, 0.0007 </td>\n   <td style=\"text-align:center;\"> 0.0007, 0.0008, 0.0008 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2: PS Correct, OR Incorrect </td>\n   <td style=\"text-align:center;\"> 0.0014, 0.0012, 0.0012 </td>\n   <td style=\"text-align:center;\"> 0.0014, 0.0012, 0.0011 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3: PS Incorrect, OR Correct </td>\n   <td style=\"text-align:center;\"> 0.0007, 0.0008, 0.0008 </td>\n   <td style=\"text-align:center;\"> 0.0007, 0.0008, 0.0009 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4: Both Incorrect </td>\n   <td style=\"text-align:center;\"> 0.0016, 0.0019, 0.0020 </td>\n   <td style=\"text-align:center;\"> 0.0016, 0.0019, 0.0020 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Funding\n\nThis work was supported by Utah Clinical & Translational Science Institute (CTSI) Translational Innovation Pilot (TIP) Program Award (NCATS UM1TR004409).\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}