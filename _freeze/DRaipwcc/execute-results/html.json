{
  "hash": "1ad14a3222d48a7c7914c4ebd8e123b6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Augmented Inverse Probability Weighted Complete Case Estimator for Survival Analysis\"\nauthor: \"Yizhe Xu^[Corresponding author: yizhe.xu@hsc.utah.edu], Peirong Hao, Ravinder Singh, Kevin Ying, Adam Bress, Tom Greene\"\ndate: \"2026-01-25\"\n#output: rmarkdown::html_vignette\noutput:\n  html_document:\n    mathjax: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nbibliography: references_DR.bib  \n#csl: harvard-cite-them-right.csl\nlink-citations: true\nobjective: Estimate treatment effects on time-to-event outcomes under informative censoring using doubly robust methods \nvignette: >\n  \\VignetteIndexEntry{Doubly Robust Estimation of Causal Effects on Time-to-event Outcomes}\n  %\\VignetteEncoding{UTF-8}\n  %\\VignetteEngine{knitr::rmarkdown}\neditor_options: \n  markdown: \n    wrap: sentence\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  message = FALSE,    \n  warning = FALSE \n)\n\nset.seed(123)\nlibrary(truncnorm)\nlibrary(survival)\nlibrary(adjustedCurves)\nlibrary(MASS)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(dagitty)\nlibrary(parallel)\nlibrary(future.apply)\nlibrary(future)\n\nn_cores <- detectCores() - 2\n```\n:::\n\n\n## Background\n\nWe continue our previous discussion on doubly robust (DR) estimators for time-to-event outcomes using [pseudo observations](https://uqualitycausal.github.io/TTECausalR/DRpseudo.html) but focus on the situation where the loss to follow-up depends on pre-baseline and post-baseline characteristics, referred to as _informative censoring_. For example, patients who are sicker at baseline or who develop treatment-related adverse events may be more likely to drop out early. In such situations, the censoring mechanism must be explicitly modeled as a function of baseline and time-dependent covariates.\n\n## Augmented Inverse Probability Weighted Complete Case Estimator\n\nWe use similar notations as before and consider $n$ independent and identically distributed individuals indexed by $i$. Let $D$ denote a binary treatment (0 or 1), $T_d$ denote the potential survival time under treatment $D=d$, $C$ the censoring time, $U_i=\\mathrm{min}(T_i, C_i)$, and $\\boldsymbol{Z}$ denotes pre-baseline covariates. \n\nLet $S_d(t)$ be the survival function under treatment $d$ at time $t$. We define the average treatment effect (ATE) as the difference in survival probabilities between treatment groups at time $t$, i.e., $S_1(t)-S_0(t)$. Without loss of generality, we focus our illustration on estimating $S_1(t)$, and $S_0(t)$ can be estimated analogously. \n\nNote that we only get to observe $T_1$ when $D=1$ and $\\Delta = 1(C \\ge T_1)$; otherwise $T_1$ is missing or coarsened. Further, this is monotone coarsening [@DR-semiparam] and we assume coarsening at random, i.e., $(D,C) \\perp T_1|Z$. Intuitively, coarsening in this case is induced by observed treatment and loss to follow-up, with treatment assignment depends only on pre-baseline characteristics and loss to follow-up relies on both pre- and post-baseline covariates, that is, informative censoring. \n\nTo handle bias induced by monotonic data coarsening, we apply the augmented inverse probability weighted Complete Case (AIPWCC) estimator described in @Bai2013. Specifically, the AIPWCC estimator  \n\n- accounts for coarsening due to treatment assignment using the **propensity score model**: $\\hat{e}(\\boldsymbol{Z})=P(D=1|Z)$\n- handles informative censoring using the treatment-specific **censoring model**: $\\hat{K}_1^c(r, Z) = P(C \\ge r|Z, D=1)$  \n- leverages the **outcome regression model** like in standard DR estimators: $\\hat{m}_1(\\boldsymbol{Z})=P(T_1>r|Z)$ \n\nThe optimal AIPWCC estimator is \n$$ \\hat{S}_1(u) = \\frac{1}{n} \\sum_{i=1}^{n} \\left[ \\frac{D_i\\mathbb{1}(U_i\\ge u)}{\\hat{e}(Z_i)\\hat{K}_1^c(u, Z_i)}-\\left\\{\\frac{D_i-\\hat{e}(Z_i)}{\\hat{e}(Z_i)} \\hat{m}_1(u, Z_i)\\right\\}+\\int_0^u \\frac{D_i}{\\hat{e}(Z_i)}\\frac{\\mathrm{d}M_{1, i}^c(r, Z_i)}{\\hat{K}_1^c(r, Z_i)}\\frac{\\hat{m}_1(u, Z_i)}{\\hat{m}_1(r, Z_i)}\\right]$$\nwhere $\\mathrm{d}M_{1, i}^c(r, Z_i) = \\frac{\\mathrm{d}N^c(r)-\\lambda_1^c(r, Z_i)Y(r)}{\\hat{K}_1^c(r, Z_i)}$ is the martingale increment for the censoring distribution with $N^c(r)=\\mathbb{1}(U\\le r, \\Delta=0)$, $Y(r)=\\mathbb{1}(U\\ge r)$, and $\\lambda_1^c(r, Z_i)=\\frac{-\\mathrm{d} \\mathrm{log}\\hat{K}_1^c(r, Z_i)}{\\mathrm{d}r}$. \n\nThe first term in the bracket in the equation above is the inverse probability weighted complete case term. The second term is the outcome-regression augmentation term in a standard DR estimator and has a mean of zero if the PS model is correct. The third term is the censoring augmentation term and also has a mean of zero if the censoring model is correct. The third term is essential to making the estimator robust to misspecification in the censoring model when the outcome model is correct. \n\nThe AIPWCC estimator is doubly robust:\n\n- If the coarsening models, including the propensity score model and censoring model, are correct \n- If the outcome model, that is, the conditional survival distribution is correct \n\nThe variance of the AIPWCC estimator for $\\hat{S}_1(u)$ can be estimated using Equation (5) in @Bai2013. If all three models (PS model, censoring model, and outcome model) are correctly specified, the estimator is locally **semiparametric efficient**, meaning it attains the smallest possible variance. One caveat is that if the outcome model or coarsening models are misspecified, the AIPWCC estimator for ATE remains unbiased, but the standard sandwich variance estimator in Equation (5) is conservative. In such cases, a bootstrap estimator of the asymptotic variance is recommended. \n\n\n## AIPWCC estimator versus pseudo-observation-based DR estimator\n\n- The pseudo-observation-based DR estimator proposed by @DR-pseudo can only be applied when loss to follow-up is completely at random \nsince the pseudo outcomes are estimated using the KM estimator where covariate adjustment is not allowed\n- Even though the pseudo-observation-based DR estimator can be extended to handle covariate-dependent censoring [@Binder2014], it models the censoring mechanism and outcome within the same model\n- In contrast, the AIPWCC estimator allows to model the censoring and outcome separately\n- In addition, the AIPWCC estimator includes an augmentation term for censoring to make it robust to censoring model misspecification and gain efficiency when the censoring model is correct\n\n\n## Implementation of the AIPWCC estimator\nWe now demonstrate how to implement the AIPWCC estimator under the informative censoring scenario.\n\n\n### Data Generation\n\nWe first simulate the data according to the variable relationships depicted in the directed acyclic graph (DAG) below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag <- dagitty(\"dag {\n  Z1 -> Treatment\n  Z2 -> Treatment\n  Z3 -> Treatment\n  Z4 -> Treatment\n  Z1 -> Death\n  Z2 -> Death\n  Z6 -> Death\n  Z7 -> Death\n  Treatment -> Death\n}\")\n\ncoordinates(dag) <- list(\n  x = c(Z3 = 0, Z4 = 0, Z1 = 1, Z2 = 1, Treatment = 1.5, Death = 3, Z6 = 4, Z7 = 4),\n  y = c(Z3 = 0.8, Z4 = 0.4, Z1 = 0.7, Z2 = 0.3, Treatment = 0.5, Death = 0.5, Z6 = 0.7, Z7 = 0.3)\n)\n\nplot(dag)\n```\n\n::: {.cell-output-display}\n![](DRaipwcc_files/figure-html/unnamed-chunk-1-1.png){width=288}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha_0 <- -0.5\nalpha_Z1 <- 2\nalpha_Z2 <- 0.5\nalpha_Z3 <- 0.5\nalpha_Z4 <- 0.5 \n\nbeta_0 <- -2.55      \nbeta_D <- -0.8 \nbeta_Z1 <- 1.25 \nbeta_Z2 <- 1.8\nbeta_Z6 <- 1.8 \nbeta_Z7 <- 1.3\n\ngenerate_data_inf <- function(n = 500) {\n  Z1 <- rtruncnorm(n, mean = 0, sd = 1, a = -0.5, b = 0.5)\n  Z2 <- rnorm(n, 0, 1)\n  Z3 <- rnorm(n, 0, 1)\n  Z4 <- rnorm(n, 0, 1)\n  Z5 <- rnorm(n, 0, 1)\n  Z6 <- rnorm(n, 0, 1)\n  Z7 <- rnorm(n, 0, 1)\n  Z8 <- rnorm(n, 0, 1)\n  Z9 <- rnorm(n, 0, 1)\n  \n  logit_p <- alpha_0 + alpha_Z1 * Z1 + alpha_Z2 * Z2 + alpha_Z3 * Z3 + alpha_Z4 * Z4\n  p <- plogis(logit_p) # exp(logit_p) / (1 + exp(logit_p))\n  D <- rbinom(n, 1, p) # Treatment indicator\n  \n  hazard <- exp(beta_0 + beta_D * D + beta_Z1 * Z1 + beta_Z2 * Z2 + beta_Z6 * Z6 + beta_Z7 * Z7)\n  T_event <- rexp(n, rate = hazard)\n  \n  hazard_cen <- exp(-2 + 0.05 * D + 0.05 * Z1 + 0.05 * Z2 + 0.05 * Z8 + 0.05 * Z9)\n  #hazard_cen <- 0.0001\n  T_censor <- rexp(n, rate = hazard_cen)\n  T_admin <- rep(5, n)\n  \n  Time <- pmin(T_event, T_censor, T_admin)\n  Event <- as.numeric(T_event <= T_censor & T_event <= T_admin)\n  #Censored <- as.numeric(T_event > T_censor & T_event <= T_admin) # Censoring indicator???\n  Censored <- 1 - Event\n  \n  return(data.frame(Z1 = Z1, Z2 = Z2, Z3 = Z3, Z4 = Z4, Z5 = Z5, Z6 = Z6, Z7 = Z7, Z8 = Z8, Z9 = Z9, D = D, Time = Time, Event = Event, Censored = Censored))\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- generate_data_inf()\n\nattr(data$Z1, \"label\") <- \"Baseline value of Z1\"\nattr(data$Z2, \"label\") <- \"Baseline value of Z2\"\nattr(data$Z3, \"label\") <- \"Baseline value of Z3\"\nattr(data$Z4, \"label\") <- \"Baseline value of Z4\"\nattr(data$Z5, \"label\") <- \"Baseline value of Z5\"\nattr(data$Z6, \"label\") <- \"Baseline value of Z6\"\nattr(data$Z7, \"label\") <- \"Baseline value of Z7\"\nattr(data$Z8, \"label\") <- \"Baseline value of Z8\"\nattr(data$Z9, \"label\") <- \"Baseline value of Z9\"\nattr(data$D, \"label\") <- \"Treatment indicator (1 = treated, 0 = control)\"\nattr(data$Time, \"label\") <- \"Time index for longitudinal records\"\nattr(data$Event, \"label\") <- \"Event indicator (1 = event occurred, 0 = otherwise)\"\n#attr(data$Censored, \"label\") <- \"Censoring indicator (1 = censored, 0 = otherwise)\"???\n\nget_label <- function(x) {\n  lbl <- attr(x, \"label\", exact = TRUE)\n  if (is.null(lbl)) \"\" else as.character(lbl)\n}\n\ndict <- data.frame(\n  Variable = names(data),\n  Meaning  = vapply(data, get_label, character(1)),\n  check.names = FALSE\n)\n\nknitr::kable(dict, caption = \"Data Dictionary\", row.names = FALSE) \n```\n\n::: {.cell-output-display}\n\n\nTable: Data Dictionary\n\n|Variable |Meaning                                             |\n|:--------|:---------------------------------------------------|\n|Z1       |Baseline value of Z1                                |\n|Z2       |Baseline value of Z2                                |\n|Z3       |Baseline value of Z3                                |\n|Z4       |Baseline value of Z4                                |\n|Z5       |Baseline value of Z5                                |\n|Z6       |Baseline value of Z6                                |\n|Z7       |Baseline value of Z7                                |\n|Z8       |Baseline value of Z8                                |\n|Z9       |Baseline value of Z9                                |\n|D        |Treatment indicator (1 = treated, 0 = control)      |\n|Time     |Time index for longitudinal records                 |\n|Event    |Event indicator (1 = event occurred, 0 = otherwise) |\n|Censored |                                                    |\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(data$Time)\n#>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n#> 0.000532 0.540231 2.077864 2.446897 5.000000 5.000000\n\ntable(data$Event)\n#> \n#>   0   1 \n#> 320 180\n\ntable(data$D)\n#> \n#>   0   1 \n#> 306 194\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncensored_subjects <- data[data$Censored == 1, ]\n(early_dropout <- sum(censored_subjects$Time < 5))\n#> [1] 182\n(admin_censored <- sum(censored_subjects$Time >= 5))\n#> [1] 138\n```\n:::\n\nAmong the 320 subjects with no events, 182 are early dropouts and 138 are administratively censored.\nAdministrative censoring is random, so no additional modeling is needed.\nEarly dropout could be covariate-dependent or occur completely at random, and we assume it is informative in this data generation.\n\nWith the simulation above, we can calculate the true survival probability.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_true_survival <- function(data, t, D) {\n  hazard <- exp(beta_0 + beta_D * D + beta_Z1 * data$Z1 + beta_Z2 * data$Z2 + beta_Z6 * data$Z6 + beta_Z7 * data$Z7)\n  survival_probs <- exp(-hazard * t) # Baseline hazard is constant under an exponential survival model\n  return(mean(survival_probs)) \n}\n```\n:::\n\n\nWe generate multiple datasets to compute the true ATEs at prespecified time points and corresponding 95% confidence intervals (CIs) using percentiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_datasets <- 100\ndatasets <- replicate(n_datasets, generate_data_inf(), simplify = FALSE)\n\ntimes <- c(1, 2, 3)\ntrue_ate_samples <- matrix(NA, nrow = n_datasets, ncol = length(times))\n\nfor (i in 1:n_datasets) {\n  # Compute potential survival probabilities by setting treatment to 1 and 0 for all individuals\n  true_surv_1 <- sapply(times, function(t) get_true_survival(datasets[[i]], t, D = 1))\n  true_surv_0 <- sapply(times, function(t) get_true_survival(datasets[[i]], t, D = 0))\n  \n  # Calculate ATE as difference in survival probabilities\n  true_ate_samples[i, ] <- true_surv_1 - true_surv_0\n}\n\ntrue_ate_mean <- colMeans(true_ate_samples)\ntrue_ate_ci_lower <- apply(true_ate_samples, 2, quantile, probs = 0.025)\ntrue_ate_ci_upper <- apply(true_ate_samples, 2, quantile, probs = 0.975)\n\nresults_true <- list(ATE = true_ate_mean, ci_lower = true_ate_ci_lower, ci_upper = true_ate_ci_upper)\n```\n:::\n\n\n### Using R package \n\nFirst, we implement the AIPWCC estimator using the _adjustedsurv_ function in the [adjustedCurves](https://cran.r-project.org/web/packages/adjustedCurves/adjustedCurves.pdf) R package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naipwcc_dr_ate_pkg <- function(data, times, ps_correct = TRUE, or_correct = TRUE, \n                              cen_correct = TRUE, variance = \"asymptotic\") {\n  \n  data$D <- factor(data$D, levels = c(0, 1))\n  \n  # Propensity score model\n  if (ps_correct) {\n    ps_model <- glm(D ~ Z1 + Z2 + Z3 + Z4, data = data, family = \"binomial\")\n  } else {\n    ps_model <- glm(D ~ Z5, data = data, family = \"binomial\")\n  }\n\n  # Censoring model \n  # Note: Event == 0 (Censored == 1) includes both loss to follow-up and administrative censoring\n  if (cen_correct) {\n    cen_model <- coxph(Surv(Time, Event == 0) ~ D + Z1 + Z2 + Z8 + Z9, data = data, x = TRUE)\n  } else {\n    cen_model <- coxph(Surv(Time, Event == 0) ~ D + Z5, data = data, x = TRUE)\n  }\n  \n  # Outcome regression (Cox proportional hazard model)\n  if (or_correct) {\n    or_model <- coxph(Surv(Time, Event) ~ D + Z1 + Z2 + Z6 + Z7, data = data, x = TRUE)\n  } else {\n    or_model <- coxph(Surv(Time, Event) ~ D + Z5, data = data, x = TRUE)\n  }\n  \n  # AIPWCC estimator for survival probabilities \n  if (variance == \"asymptotic\") { # Use asymptotic variance\n    adj_surv <- adjustedsurv(\n      data = data,\n      variable = \"D\",\n      ev_time = \"Time\",\n      event = \"Event\",\n      method = \"aiptw\",\n      treatment_model = ps_model,\n      censoring_model = cen_model,\n      outcome_model = or_model,\n      times = times, \n      conf_int = TRUE,\n      conf_level = 0.95,\n      bootstrap = FALSE) \n  } else if (variance == \"bootstrap\"){ # Use bootstrap variance\n    adj_surv <- adjustedsurv(\n      data = data,\n      variable = \"D\",\n      ev_time = \"Time\",\n      event = \"Event\",\n      method = \"aiptw\",\n      treatment_model = ps_model,\n      censoring_model = cen_model,\n      outcome_model = or_model,\n      times = times,\n      conf_int = TRUE,\n      conf_level = 0.95,\n      bootstrap = TRUE,\n      n_boot = 100) \n  }\n    \n  # Treatment effect is defined as the difference in survival probabilities.\n  ate_results <- adjusted_curve_diff(\n    adj = adj_surv,\n    group_1 = \"1\",  # Treated group\n    group_2 = \"0\",  # Control group\n    conf_int = TRUE,\n    conf_level = 0.95)\n  \n  # Extract survival probabilities at times of interest\n  ate_at_times <- ate_results[ate_results$time %in% times, ]\n  \n  return(list(ATE = ate_at_times$diff, ci_lower = ate_at_times$ci_lower, ci_upper = ate_at_times$ci_upper))\n}\n```\n:::\n\n\nWe estimate the ATEs at prespecified time points and corresponding 95% confidence intervals (CIs).\n\n::: {.cell}\n\n```{.r .cell-code}\nresults_asymp <- aipwcc_dr_ate_pkg(data, times, variance = \"asymptotic\")\n# results_boot <- aipwcc_dr_ate_pkg(data, times, variance = \"bootstrap\")\n# \n# results_package_tbl <- data.frame(\n#   Time = paste0(\"T = \", times),\n#   True = sprintf(\"%.3f (%.3f, %.3f)\", results_true$ATE, results_true$ci_lower, results_true$ci_upper),\n#   Asymptotic = sprintf(\"%.3f (%.3f, %.3f)\", results_asymp$ATE, results_asymp$ci_lower, results_asymp$ci_upper),\n#   Bootstrap = sprintf(\"%.3f (%.3f, %.3f)\", results_boot$ATE, results_boot$ci_lower, results_boot$ci_upper)\n# )\n# \n# kable(results_package_tbl,\n#       caption = \"ATE (95% CI)\",\n#       col.names = c(\"Time\", \"True\", \"Asymptotic\", \"Bootstrap\"),\n#       align = c('c', 'c', 'c', 'c')) %>%\n#   kable_styling(full_width = FALSE, font_size = 12)\n```\n:::\n\n\n### Crude estimation\n\nFit a crude Cox model with no covariate or propensity score adjustment to show the amount of confounding bias in our data\n\n::: {.cell}\n\n```{.r .cell-code}\ncrude_cox_estimator <- function(data, times) {\n  crude_cox <- coxph(Surv(Time, Event) ~ D, data = data)\n  treatment_effect <- coef(crude_cox)[\"D\"]\n  \n  base_surv <- survfit(crude_cox)\n  s0 <- summary(base_surv, times = times, extend = TRUE)$surv\n  \n  # Survival for treated group: S_baseline^exp(beta_D)\n  surv_1 <- s0^exp(treatment_effect)\n  \n  # Survival for control group: S_baseline^exp(0) \n  surv_0 <- s0\n\n  ATE <- surv_1 - surv_0\n  return(list(ATE = ATE))\n}\n\nresults_crude <- crude_cox_estimator(data, times)\n```\n:::\n\n\n### Evaluate the performance of AIPWCC estimator\n\nWe use the datasets generated previously to calculate RMSE, bias, and variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = n_cores)\n\ncalculate_metrics <- function(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\", \n                              ps_correct = TRUE, or_correct = TRUE, cen_correct = TRUE) {\n  \n  n_datasets <- length(datasets)\n  \n  ate <- future_lapply(1:n_datasets, function(i) {\n    library(survival)\n    library(adjustedCurves)\n    \n    est_results <- switch(\n      method,\n      \"package\" = aipwcc_dr_ate_pkg(datasets[[i]], times, variance = variance, \n                                    ps_correct = ps_correct, or_correct = or_correct, cen_correct = cen_correct),\n      \"crude\" = crude_cox_estimator(datasets[[i]], times),\n      stop(\"Unknown: \", method))\n    \n    est_results$ATE\n  }, future.seed = TRUE)\n  \n  ate_all <- do.call(rbind, ate)\n  \n  bias <- colMeans(ate_all - true_ate_samples)\n  variance <- apply(ate_all, 2, var)\n  rmse <- sqrt(colMeans((ate_all - true_ate_samples)^2))\n  \n  return(list(bias = bias, variance = variance, rmse = rmse))\n}\n```\n:::\n\n\n### Model misspecification scenarios\n\nTo illustrate the robustness of the AIPWCC estimator to model misspecification, we compare the following scenarios:\n\n-   Scenario 1: The outcome model, the propensity score model, and the censoring model are all correctly specified\n\n-   Scenario 2: The outcome model and propensity score model are correctly specified, while the censoring model is misspecified\n\n-   Scenario 3: The outcome model and censoring model are correctly specified, while the propensity score model is misspecified\n\n-   Scenario 4: The outcome model is correctly specified, while the propensity score model and censoring model are both misspecified\n\n-   Scenario 5: The propensity score model and censoring model are correctly specified, but the outcome model is misspecified\n\n-   Scenario 6: The propensity score model is correctly specified, but the outcome model and censoring model are both misspecified\n\n-   Scenario 7: The censoring model is correctly specified, but the outcome model and propensity score model are both misspecified\n\n-   Scenario 8: All three models are misspecified\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scenario 1: All models correct\nmetrics_1_asymp <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\",\n                                     ps_correct = TRUE, cen_correct = TRUE, or_correct = TRUE)\n# metrics_1_boot <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"bootstrap\",\n#                                     ps_correct = TRUE, cen_correct = TRUE, or_correct = TRUE)\n\n# Scenario 2: PS correct, Cen incorrect, OR correct\nmetrics_2_asymp <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\",\n                                     ps_correct = TRUE, cen_correct = FALSE, or_correct = TRUE)\n# metrics_2_boot <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"bootstrap\",\n#                                     ps_correct = TRUE, cen_correct = FALSE, or_correct = TRUE)\n\n# Scenario 3: PS incorrect, Cen correct, OR correct\nmetrics_3_asymp <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\",\n                                     ps_correct = FALSE, cen_correct = TRUE, or_correct = TRUE)\n# metrics_3_boot <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"bootstrap\",\n#                                     ps_correct = FALSE, cen_correct = TRUE, or_correct = TRUE)\n\n# Scenario 4: PS incorrect, Cen incorrect, OR correct\nmetrics_4_asymp <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\",\n                                     ps_correct = FALSE, cen_correct = FALSE, or_correct = TRUE)\n# metrics_4_boot <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"bootstrap\",\n#                                     ps_correct = FALSE, cen_correct = FALSE, or_correct = TRUE)\n\n# Scenario 5: PS correct, Cen correct, OR incorrect\nmetrics_5_asymp <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\",\n                                     ps_correct = TRUE, cen_correct = TRUE, or_correct = FALSE)\n# metrics_5_boot <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"bootstrap\",\n#                                     ps_correct = TRUE, cen_correct = TRUE, or_correct = FALSE)\n\n# Scenario 6: PS correct, Cen incorrect, OR incorrect\nmetrics_6_asymp <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\",\n                                     ps_correct = TRUE, cen_correct = FALSE, or_correct = FALSE)\n# metrics_6_boot <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"bootstrap\",\n#                                     ps_correct = TRUE, cen_correct = FALSE, or_correct = FALSE)\n\n# Scenario 7: PS incorrect, Cen correct, OR incorrect\nmetrics_7_asymp <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\",\n                                     ps_correct = FALSE, cen_correct = TRUE, or_correct = FALSE)\n# metrics_7_boot <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"bootstrap\",\n#                                     ps_correct = FALSE, cen_correct = TRUE, or_correct = FALSE)\n\n# Scenario 8: All models incorrect\nmetrics_8_asymp <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"asymptotic\",\n                                     ps_correct = FALSE, cen_correct = FALSE, or_correct = FALSE)\n# metrics_8_boot <- calculate_metrics(datasets, true_ate_samples, times, method = \"package\", variance = \"bootstrap\",\n#                                     ps_correct = FALSE, cen_correct = FALSE, or_correct = FALSE)\n\n# Scenario 0: Crude Cox\nmetrics_crude <- calculate_metrics(datasets, true_ate_samples, times, method = \"crude\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscenarios <- c(\"1: All Correct\",\n  \"2: PS Correct, Cen Incorrect, OR Correct\",\n  \"3: PS Incorrect, Cen Correct, OR Correct\",\n  \"4: PS Incorrect, Cen Incorrect, OR Correct\",\n  \"5: PS Correct, Cen Correct, OR Incorrect\",\n  \"6: PS Correct, Cen Incorrect, OR Incorrect\",\n  \"7: PS Incorrect, Cen Correct, OR Incorrect\",\n  \"8: All Incorrect\")\n\n# Combine values across all time points into a single string\nformat_values <- function(vec) {\n  paste(sprintf(\"%.4f\", vec), collapse = \", \")\n}\n\n# RMSE table\nrmse_asymp <- c(format_values(metrics_1_asymp$rmse), format_values(metrics_2_asymp$rmse), \n                format_values(metrics_3_asymp$rmse), format_values(metrics_4_asymp$rmse),\n                format_values(metrics_5_asymp$rmse), format_values(metrics_6_asymp$rmse), \n                format_values(metrics_7_asymp$rmse), format_values(metrics_8_asymp$rmse))\nrmse_asymp\n#> [1] \"0.0290, 0.0279, 0.0295\" \"0.0290, 0.0279, 0.0296\" \"0.0278, 0.0282, 0.0294\"\n#> [4] \"0.0277, 0.0281, 0.0294\" \"0.0401, 0.0411, 0.0428\" \"0.0400, 0.0409, 0.0427\"\n#> [7] \"0.0985, 0.1058, 0.1113\" \"0.0984, 0.1058, 0.1112\"\n# rmse_boot <- c(format_values(metrics_1_boot$rmse), format_values(metrics_2_boot$rmse),\n#                format_values(metrics_3_boot$rmse), format_values(metrics_4_boot$rmse),\n#                format_values(metrics_5_boot$rmse), format_values(metrics_6_boot$rmse),\n#                format_values(metrics_7_boot$rmse), format_values(metrics_8_boot$rmse))\n# \n# rmse_table <- data.frame(Scenario = scenarios, Asymptotic = rmse_asymp, Bootstrap = rmse_boot)\n# \n# kable(rmse_table,\n#       col.names = c(\"Scenario\", \"T = 1, 2, 3\", \"T = 1, 2, 3\"),\n#       caption = \"Performance of the estimator (RMSE)\",\n#       align = c('c', 'c', 'c')) %>%\n#   kable_styling(full_width = FALSE, font_size = 12) %>%\n#   add_header_above(c(\" \" = 1, \"Asymptotic\" = 1, \"Bootstrap\" = 1)) %>%\n#   footnote(general = paste0(\"Crude Cox: \", format_values(metrics_crude$rmse)), general_title = \"\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bias table\nbias_asymp <- c(format_values(metrics_1_asymp$bias), format_values(metrics_2_asymp$bias), \n                format_values(metrics_3_asymp$bias), format_values(metrics_4_asymp$bias),\n                format_values(metrics_5_asymp$bias), format_values(metrics_6_asymp$bias), \n                format_values(metrics_7_asymp$bias), format_values(metrics_8_asymp$bias))\nbias_asymp\n#> [1] \"-0.0037, 0.0017, -0.0002\"  \"-0.0037, 0.0017, -0.0001\" \n#> [3] \"-0.0049, 0.0005, 0.0008\"   \"-0.0048, 0.0004, 0.0007\"  \n#> [5] \"-0.0051, 0.0006, -0.0011\"  \"-0.0050, 0.0006, -0.0010\" \n#> [7] \"-0.0894, -0.0966, -0.1017\" \"-0.0893, -0.0966, -0.1017\"\n# bias_boot <- c(format_values(metrics_1_boot$bias), format_values(metrics_2_boot$bias),\n#                format_values(metrics_3_boot$bias), format_values(metrics_4_boot$bias),\n#                format_values(metrics_5_boot$bias), format_values(metrics_6_boot$bias),\n#                format_values(metrics_7_boot$bias), format_values(metrics_8_boot$bias))\n# \n# bias_table <- data.frame(Scenario = scenarios, Asymptotic = bias_asymp, Bootstrap = bias_boot)\n# \n# kable(bias_table,\n#       col.names = c(\"Scenario\", \"T = 1, 2, 3\", \"T = 1, 2, 3\"),\n#       caption = \"Performance of the estimator (Bias)\",\n#       align = c('c', 'c', 'c')) %>%\n#   kable_styling(full_width = FALSE, font_size = 12) %>%\n#   add_header_above(c(\" \" = 1, \"Asymptotic\" = 1, \"Bootstrap\" = 1)) %>%\n#   footnote(general = paste0(\"Crude Cox: \", format_values(metrics_crude$bias)), general_title = \"\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Variance table\nvar_asymp <- c(format_values(metrics_1_asymp$variance), format_values(metrics_2_asymp$variance), \n               format_values(metrics_3_asymp$variance), format_values(metrics_4_asymp$variance),\n               format_values(metrics_5_asymp$variance), format_values(metrics_6_asymp$variance), \n               format_values(metrics_7_asymp$variance), format_values(metrics_8_asymp$variance))\nvar_asymp\n#> [1] \"0.0008, 0.0008, 0.0009\" \"0.0008, 0.0008, 0.0009\" \"0.0007, 0.0008, 0.0009\"\n#> [4] \"0.0007, 0.0008, 0.0009\" \"0.0016, 0.0017, 0.0018\" \"0.0016, 0.0017, 0.0018\"\n#> [7] \"0.0017, 0.0019, 0.0021\" \"0.0017, 0.0019, 0.0020\"\n# var_boot <- c(format_values(metrics_1_boot$variance), format_values(metrics_2_boot$variance),\n#               format_values(metrics_3_boot$variance), format_values(metrics_4_boot$variance),\n#               format_values(metrics_5_boot$variance), format_values(metrics_6_boot$variance),\n#               format_values(metrics_7_boot$variance), format_values(metrics_8_boot$variance))\n# \n# var_table <- data.frame(Scenario = scenarios, Asymptotic = var_asymp, Bootstrap = var_boot)\n# \n# kable(var_table,\n#       col.names = c(\"Scenario\", \"T = 1, 2, 3\", \"T = 1, 2, 3\"),\n#       caption = \"Performance of the estimator (Variance)\",\n#       align = c('c', 'c', 'c')) %>%\n#   kable_styling(full_width = FALSE, font_size = 12) %>%\n#   add_header_above(c(\" \" = 1, \"Asymptotic\" = 1, \"Bootstrap\" = 1)) %>%\n#   footnote(general = paste0(\"Crude Cox: \", format_values(metrics_crude$variance)), general_title = \"\")\n```\n:::\n\n\n## Funding\n\nThis work was supported by Utah Clinical & Translational Science Institute (CTSI) Translational Innovation Pilot (TIP) Program Award (NCATS UM1TR004409).\n\n## References",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}